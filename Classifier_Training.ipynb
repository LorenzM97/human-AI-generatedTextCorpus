{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda4a185",
   "metadata": {
    "id": "cda4a185"
   },
   "source": [
    "# Notebook to Train the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05ade2",
   "metadata": {
    "id": "be05ade2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import logging\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zGAAAuKE_16J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGAAAuKE_16J",
    "outputId": "f942e3ff-e778-497c-e6a3-fd9c9919ddf9"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f4db0",
   "metadata": {},
   "source": [
    "### if trained in Colab, and personal drive should be mounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8UvnO1oL_7CH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UvnO1oL_7CH",
    "outputId": "4ee29b58-446e-43b6-cdf7-3017aa34ad6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb5d1e",
   "metadata": {
    "id": "00fb5d1e"
   },
   "source": [
    "# List of Features per Feature Category\n",
    "Two types of lists created per feature category: Only traditional feature & traditional+new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062b00a",
   "metadata": {
    "id": "4062b00a"
   },
   "outputs": [],
   "source": [
    "# Feature groups\n",
    "PPL_based = ['ppl_max', 'ppl_mean']\n",
    "\n",
    "Semantic_feat = ['sentiment_polarity', 'sentiment_subjectivity']\n",
    "list_lookup_trad = ['stop_word_count','personal_pronoun_relative', 'personal_pronoun_count']\n",
    "list_lookup_all = ['discourse_marker_count', 'stop_word_count','title_repetition_count',\n",
    "                   'title_repetition_relative','personal_pronoun_relative', 'personal_pronoun_count']\n",
    "\n",
    "error_based = ['grammar_error_count','multi_blank_count',]\n",
    "\n",
    "readability = ['flesch_reading_ease', 'flesch_kincaid_grade_level',]\n",
    "\n",
    "AI_feedback = ['ai_feedback']\n",
    "\n",
    "text_vector = ['sentence_bert', 'sentence_bert_dist', 'tfidf']\n",
    "\n",
    "doc_and_corp = ['words_per_paragraph_mean', 'words_per_paragraph_stdev',\n",
    "                'sentences_per_paragraph_mean', 'sentences_per_paragraph_stdev',\n",
    "                'words_per_sentence_mean', 'words_per_sentence_stdev',\n",
    "                'unique_words_per_sentence_mean', 'unique_words_per_sentence_stdev',\n",
    "                'character_count','words_count','unique_words_count', 'unique_words_relative',\n",
    "                'sentence_count','punctuation_count', 'paragraph_count','quotation_count',\n",
    "                'pos_per_sentence_mean', 'uppercase_letters_relative', 'special_char_count',]\n",
    "doc_and_corp_trad = ['words_per_paragraph_mean', 'words_per_paragraph_stdev',\n",
    "                    'sentences_per_paragraph_mean', 'sentences_per_paragraph_stdev',\n",
    "                    'words_per_sentence_mean', 'words_per_sentence_stdev',\n",
    "                    'unique_words_per_sentence_mean','character_count','words_count','unique_words_count', \n",
    "                    'unique_words_relative', 'sentence_count','punctuation_count', 'paragraph_count',\n",
    "               'pos_per_sentence_mean', 'uppercase_letters_relative', 'special_char_count']\n",
    "\n",
    "all_f = PPL_based + Semantic_feat+list_lookup_all+error_based+readability+AI_feedback+text_vector+doc_and_corp\n",
    "all_trad = ['sentence_bert', 'tfidf', 'flesch_reading_ease', 'flesch_kincaid_grade_level','words_per_paragraph_mean',\n",
    "            'words_per_paragraph_stdev', 'sentences_per_paragraph_mean', 'sentences_per_paragraph_stdev',\n",
    "            'words_per_sentence_mean', 'words_per_sentence_stdev', 'unique_words_per_sentence_mean',\n",
    "            'character_count','words_count','unique_words_count', 'unique_words_relative',\n",
    "            'sentence_count','punctuation_count', 'paragraph_count', 'personal_pronoun_relative',\n",
    "            'personal_pronoun_count','pos_per_sentence_mean', 'uppercase_letters_relative', 'special_char_count',\n",
    "            'stop_word_count', 'sentiment_polarity',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97814d",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76beba",
   "metadata": {
    "id": "1e76beba"
   },
   "outputs": [],
   "source": [
    "# Returns datasets for one on the five folds\n",
    "\n",
    "def get_datasets(df, fold):\n",
    "    filtered_df_train = df.loc[df[\"Fold_{}\".format(fold)] == \"train\"]\n",
    "    filtered_df_val = df.loc[df[\"Fold_{}\".format(fold)] == \"val\"]\n",
    "    filtered_df_test = df.loc[df[\"Fold_{}\".format(fold)] == \"test\"]\n",
    "\n",
    "    train_labels = filtered_df_train['author'].to_numpy()\n",
    "    val_labels = filtered_df_val['author'].to_numpy()\n",
    "    test_labels = filtered_df_test['author'].to_numpy()\n",
    "\n",
    "    train_df_selected = filtered_df_train.drop(columns=['author', 'Fold_1', 'Fold_2', 'Fold_3', 'Fold_4','Fold_5'])\n",
    "    train_features_arr = np.array(train_df_selected)\n",
    "\n",
    "    val_df_selected = filtered_df_val.drop(columns=['author', 'Fold_1', 'Fold_2', 'Fold_3', 'Fold_4','Fold_5'])\n",
    "    val_features_arr = np.array(val_df_selected)\n",
    "\n",
    "    test_df_selected = filtered_df_test.drop(columns=['author', 'Fold_1', 'Fold_2', 'Fold_3', 'Fold_4','Fold_5'])\n",
    "    test_features_arr = np.array(test_df_selected)\n",
    "\n",
    "    # labels to numbers\n",
    "    train_labels = np.where(train_labels == \"human\", 0, 1)\n",
    "    val_labels = np.where(val_labels == \"human\", 0, 1)\n",
    "    test_labels = np.where(test_labels == \"human\", 0, 1)\n",
    "\n",
    "    return train_features_arr, train_labels, val_features_arr, val_labels, test_features_arr, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f17ff7",
   "metadata": {
    "id": "90f17ff7"
   },
   "outputs": [],
   "source": [
    "# Logging of the results\n",
    "\n",
    "def log_results(modeltype,data,feature,fold,acc,f1,best_params ,time):\n",
    "    # Open CSV file in append mode\n",
    "    with open('drive/MyDrive/Models/model_trainings_log.csv', mode='a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "\n",
    "        # Log a message and write to CSV file\n",
    "        logging.info('This is a log message.')\n",
    "        writer.writerow([modeltype,data,feature,fold,acc,f1,best_params ,time])\n",
    "\n",
    "def log_run_metrics(modeltype,data,feature,avg_acc, avg_f1, lang, source, time):\n",
    "    # Open CSV file in append mode\n",
    "    with open('drive/MyDrive/Models/train_run_results.csv', mode='a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "\n",
    "        # Log a message and write to CSV file\n",
    "        logging.info('This is a log message.')\n",
    "        writer.writerow([modeltype,data,feature,avg_acc, avg_f1, lang, source, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95a0e2",
   "metadata": {
    "id": "0e95a0e2"
   },
   "outputs": [],
   "source": [
    "# functions to train XGBoost, Random Forest, and the Neural Network\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam, SGD\n",
    "import csv\n",
    "import logging\n",
    "\n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int(\"num_layers\", 2, 5)):\n",
    "        model.add(keras.layers.Dense(\n",
    "          hp.Choice('units', [16, 32,64]),\n",
    "          activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_nn(X_train, y_train, X_val, y_val, X_test, y_test, fold, data, feature):\n",
    "\n",
    "    now = datetime.now()\n",
    "    time_now = now.strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "    tuner = keras_tuner.GridSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=25, directory = \"./drive/MyDrive/Models/NN/{}/\".format(time_now))\n",
    "\n",
    "    X_train = np.asarray(X_train).astype('float32')\n",
    "    X_val = np.asarray(X_val).astype('float32')\n",
    "    X_test = np.asarray(X_test).astype('float32')\n",
    "\n",
    "    # normalize data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    tuner.search(X_train, y_train, epochs=25, validation_data=(X_val, y_val))\n",
    "    best_model = tuner.get_best_models()[0]\n",
    "\n",
    "    preds = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score on the test data\n",
    "    accuracy_test = accuracy_score(y_test, (preds > 0.5))\n",
    "    f1 = f1_score(y_test, (preds > 0.5))\n",
    "\n",
    "    best_params = {\"units\": tuner.get_best_hyperparameters()[0].get(\"units\"),\n",
    "                   \"num_layers\": tuner.get_best_hyperparameters()[0].get(\"num_layers\")}\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "    log_results(\"NN\", data,feature, fold,accuracy_test, f1, best_params, time_now)\n",
    "\n",
    "    print(\"Test accuracy:\", accuracy_test)\n",
    "\n",
    "    return accuracy_test, f1\n",
    "\n",
    "\n",
    "def train_rf():\n",
    "    # Set up the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 500, 1000],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'max_leaf_nodes': [3, 6, 9]\n",
    "    }\n",
    "\n",
    "    # Create a random forest classifier\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    return rf, param_grid\n",
    "\n",
    "\n",
    "def train_xgb():\n",
    "    # Set up the parameter grid to search over\n",
    "    param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 250, 500, 750],\n",
    "    'lambda': [1.25, 2],\n",
    "    'alpha': [0.25, 0.75]\n",
    "    }\n",
    "\n",
    "    # Create an instance of the XGBoost classifier\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "    return xgb, param_grid\n",
    "\n",
    "\n",
    "def train_ml_approaches(X_train, y_train, X_val, y_val, X_test, y_test, fold, data, feature, model_type):\n",
    "    \"\"\"\n",
    "    Trains and hyperparameter tunes a binary random forest classifier using GridSearchCV\n",
    "    with train, validation, and test datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    now = datetime.now()\n",
    "    time_now = now.strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "    X = np.concatenate((X_train, X_val))\n",
    "    y = np.concatenate((y_train, y_val))\n",
    "\n",
    "    X = np.asarray(X).astype('float32')\n",
    "    y = np.asarray(y).astype('float32')\n",
    "\n",
    "    val_fold = [-1] * len(X)\n",
    "    for i, value in enumerate(val_fold):\n",
    "        if i > len(X_train):\n",
    "            val_fold[i] = 0\n",
    "\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "\n",
    "    if model_type == \"rf\":\n",
    "        classifier, param_grid = train_rf()\n",
    "    elif model_type == \"xgb\":\n",
    "        classifier, param_grid = train_xgb()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=ps, scoring='accuracy',n_jobs=50)\n",
    "\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "    # Predict on the validation data\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "    # Calculate the accuracy score on the validation data\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "    print(\"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score on the test data\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    log_results(model_type, data,\n",
    "                feature, fold,\n",
    "                accuracy_test, f1,\n",
    "                grid_search.best_params_\n",
    "                , time_now)\n",
    "\n",
    "    print(\"Test accuracy:\", accuracy_test)\n",
    "\n",
    "    return accuracy_test, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db92a56",
   "metadata": {
    "id": "0db92a56"
   },
   "outputs": [],
   "source": [
    "# Run training for all 3 classifiers\n",
    "\n",
    "def define_and_exec_run(features_list, feature_name, gpt_data, wiki_path, gpt_path, data, lang):\n",
    "\n",
    "    now = datetime.now()\n",
    "    time_now = now.strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "    features = features_list.copy()\n",
    "    wiki_features_df = pd.read_pickle(wiki_path)\n",
    "    gpt_features_df = pd.read_pickle(gpt_path)\n",
    "\n",
    "    gpt_features_df = gpt_features_df[gpt_features_df[\"source\"] == gpt_data]\n",
    "\n",
    "    # if tf idf and/or sentence bert used, this list contains the new column names\n",
    "    tf_idf_col_names = []\n",
    "    sent_bert_col_names = []\n",
    "\n",
    "    if \"tfidf\" in features:\n",
    "        col_name_wiki = \"tfidf_{}\".format(gpt_data)\n",
    "\n",
    "        for i in range(len(wiki_features_df[col_name_wiki].iloc[0])):\n",
    "            wiki_features_df[f'tfidf{i+1}'] = wiki_features_df[col_name_wiki].apply(lambda x: x[i] if i < len(x) else None)\n",
    "        wiki_features_df = wiki_features_df.drop(columns=[\"tfidf_rephrase_base\", \"tfidf_rephrase_expert\", \"tfidf_generated_base\", \"tfidf_generated_expert\"])\n",
    "\n",
    "        for i in range(len(gpt_features_df[\"tfidf\"].iloc[0])):\n",
    "            gpt_features_df[f'tfidf{i+1}'] = gpt_features_df[\"tfidf\"].apply(lambda x: x[i] if i < len(x) else None)\n",
    "            tf_idf_col_names.append(\"tfidf{}\".format(i+1))\n",
    "        gpt_features_df = gpt_features_df.drop(columns=[\"tfidf\"])\n",
    "\n",
    "        # drop initial feature\n",
    "        features.remove(\"tfidf\")\n",
    "\n",
    "\n",
    "    df = pd.concat((wiki_features_df, gpt_features_df))\n",
    "    print(df)\n",
    "\n",
    "    if \"sentence_bert\" in features:\n",
    "        for i in range(len(df[\"sentence_bert\"].iloc[0])):\n",
    "            df[f'sentence_bert{i+1}'] = df[\"sentence_bert\"].apply(lambda x: x[i] if i < len(x) else None)\n",
    "            sent_bert_col_names.append(\"sentence_bert{}\".format(i+1))\n",
    "        df = df.drop(columns=[\"sentence_bert\"])\n",
    "\n",
    "        # drop initial feature\n",
    "        features.remove(\"sentence_bert\")\n",
    "\n",
    "    print(features)\n",
    "    print(sent_bert_col_names)\n",
    "    print(tf_idf_col_names)\n",
    "\n",
    "    train_df = df[features\n",
    "                     + [\"author\", \"Fold_1\", \"Fold_2\", \"Fold_3\", \"Fold_4\", \"Fold_5\"]\n",
    "                     + sent_bert_col_names\n",
    "                     + tf_idf_col_names]\n",
    "    print(train_df.shape)\n",
    "    print(train_df)\n",
    "\n",
    "    print(\"RF run for {} with name {} and features {}\".format(gpt_data, feature_name, features))\n",
    "    metrics = []\n",
    "    for i in range(1,6):\n",
    "        print(\"Iteration {}\".format(i))\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = get_datasets(train_df, i)\n",
    "\n",
    "        acc, f1 = train_ml_approaches(x_train, y_train, x_val, y_val, x_test, y_test, i, gpt_data, features, \"rf\")\n",
    "        metrics.append([acc, f1])\n",
    "\n",
    "    avg_metrics = np.average(metrics,axis=0)\n",
    "    log_run_metrics(\"rf\", gpt_data, feature_name, avg_metrics[0], avg_metrics[1], lang, data, time_now)\n",
    "\n",
    "\n",
    "    print(\"XGB run for {} with name {} and features {}\".format(gpt_data, feature_name, features))\n",
    "    metrics = []\n",
    "    for i in range(1,6):\n",
    "        print(\"Iteration {}\".format(i))\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = get_datasets(train_df, i)\n",
    "\n",
    "        acc, f1 = train_ml_approaches(x_train, y_train, x_val, y_val, x_test, y_test, i, gpt_data, features, \"xgb\")\n",
    "        metrics.append([acc, f1])\n",
    "\n",
    "    avg_metrics = np.average(metrics,axis=0)\n",
    "    log_run_metrics(\"xgb\", gpt_data, feature_name, avg_metrics[0], avg_metrics[1], lang, data, time_now)\n",
    "\n",
    "\n",
    "    print(\"NN run for {} with name {} and features {}\".format(gpt_data, feature_name, features))\n",
    "    metrics = []\n",
    "    for i in range(1,6):\n",
    "        print(\"Iteration {}\".format(i))\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = get_datasets(train_df, i)\n",
    "        print('Training Features Shape:', x_train.shape)\n",
    "\n",
    "        acc, f1 = train_nn(x_train, y_train, x_val, y_val, x_test, y_test, i, gpt_data, features)\n",
    "        metrics.append([acc, f1])\n",
    "\n",
    "    avg_metrics = np.average(metrics,axis=0)\n",
    "    log_run_metrics(\"nn\", gpt_data, feature_name, avg_metrics[0], avg_metrics[1], lang, data, time_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gonYqNEtBk69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gonYqNEtBk69",
    "outputId": "81ea3c2b-f276-4311-9452-130d251cc75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.8500000238418579\n",
      "\n",
      "Best val_accuracy So Far: 0.8999999761581421\n",
      "Total elapsed time: 00h 00m 53s\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "Best hyperparameters: {'units': 32, 'num_layers': 5}\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "wiki_path = \"human_generated.pkl\"\n",
    "gpt_path=\"ai_generated.pkl\"\n",
    "lang=\"en\"\n",
    "data=\"wiki\"\n",
    "\n",
    "gpt_data=\"generated_base\"\n",
    "define_and_exec_run(all_trad, \"all_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(all_f, \"all_with_new\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(['sentence_bert', 'tfidf'], \"text_vector_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(text_vector, \"text_vector_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "\n",
    "gpt_data=\"rephrase_base\"\n",
    "define_and_exec_run(all_trad, \"all_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(all_f, \"all_with_new\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(['sentence_bert', 'tfidf'], \"text_vector_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(text_vector, \"text_vector_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "\n",
    "gpt_data=\"generated_expert\"\n",
    "define_and_exec_run(all_trad, \"all_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(all_f, \"all_with_new\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(['sentence_bert', 'tfidf'], \"text_vector_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(text_vector, \"text_vector_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "\n",
    "gpt_data=\"rephrase_expert\"\n",
    "define_and_exec_run(all_trad, \"all_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(all_f, \"all_with_new\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(['sentence_bert', 'tfidf'], \"text_vector_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(text_vector, \"text_vector_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HEWAMeNL4YjQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "HEWAMeNL4YjQ",
    "outputId": "3cbbb5ae-3adc-4bfe-e9b0-c8ee3670173b"
   },
   "outputs": [],
   "source": [
    "wiki_path = \"human_generated.pkl\"\n",
    "gpt_path=\"ai_generated.pkl\"\n",
    "lang=\"en\"\n",
    "data=\"wiki\"\n",
    "gpt_data=\"rephrase_expert\"\n",
    "\n",
    "define_and_exec_run(PPL_based, \"PPL_based\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(['sentiment_polarity'], \"semantic_traditional\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(Semantic_feat, \"semantic_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(list_lookup_trad, \"list_lookup_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(list_lookup_all, \"list_lookup_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(doc_and_corp_trad, \"doc_and_corp_traditional\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(doc_and_corp, \"doc_and_corp_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(error_based, \"error_based\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(readability, \"readability_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(AI_feedback, \"AI_feedback\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(['sentence_bert', 'tfidf'], \"text_vector_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(text_vector, \"text_vector_all\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(all_trad, \"all_trad\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n",
    "define_and_exec_run(all_f, \"all_with_new\", gpt_data, wiki_path=wiki_path, gpt_path=gpt_path, lang=lang, data=data)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
