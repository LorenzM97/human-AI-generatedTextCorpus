{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e09d025",
   "metadata": {},
   "source": [
    "# Featurea Derivation for the Different Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.helper_functions as helper_functions\n",
    "from collections import Counter\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334e5c8",
   "metadata": {},
   "source": [
    "### Load Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140880aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_wiki_features_df =  pd.read_pickle(\"human_generated.pkl\")\n",
    "gpt_features_df =  pd.read_pickle(\"ai_generated.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b4165",
   "metadata": {},
   "source": [
    "# Derive TF-IDF Feature\n",
    "Process: TF-IDF derived for human-generated texts and subset of AI-generated texts (e.g., basic AI-rephrased texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "729cf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_top_indices_and_vectorizer(texts):\n",
    "    # Initialize the TfidfVectorizer with uni- and bigram options\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    \n",
    "    # Fit the vectorizer on the texts\n",
    "    tfidf.fit(texts)\n",
    "    \n",
    "    # Get the feature names (uni- and bigrams)\n",
    "    feature_names = tfidf.get_feature_names()\n",
    "\n",
    "    # Get the document-term matrix (DTM) of the corpus\n",
    "    dtm = tfidf.transform(texts)\n",
    "\n",
    "    # Get the sum of the tf-idf scores for each feature across all documents\n",
    "    sum_tfidf = dtm.sum(axis=0)\n",
    "\n",
    "    # Convert the DTM to a dense matrix for easier manipulation\n",
    "    dense_dtm = dtm.todense()\n",
    "\n",
    "    # Get the indices of the top 500 features with the highest tf-idf scores\n",
    "    top_indices = sum_tfidf.argsort()[0, -500:]\n",
    "    top_indices = top_indices.tolist()[0]\n",
    "    top_features = []\n",
    "    # Get the feature names (uni- and bigrams) of the top 500 features\n",
    "    for top_val in top_indices:\n",
    "        top_features.append(feature_names[top_val])\n",
    "        \n",
    "    return tfidf, top_indices, top_features\n",
    "\n",
    "def calc_tfidf(text, vectorizer, top_indices):\n",
    "    # Transform the new document into a DTM\n",
    "    new_dtm = vectorizer.transform([text])\n",
    "\n",
    "    # Get the tf-idf scores for the top 500 features of the new document\n",
    "    new_tfidf = [new_dtm[0, i] for i in top_indices]\n",
    "    \n",
    "    return new_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b06ab",
   "metadata": {},
   "source": [
    "#### Define Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99e0a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = de_wiki_features_df.copy()\n",
    "gpt_df = de_gpt_features_df.copy()\n",
    "gpt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb528d",
   "metadata": {},
   "source": [
    "#### Define Type of AI-written text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "767c423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_source = \"generated_base\"\n",
    "gpt_filtered = gpt_df[gpt_df[\"source\"] == gpt_source]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c886ee",
   "metadata": {},
   "source": [
    "#### Combine human-generated and AI-written texts\n",
    "Should be 100 human- and 100 AI-texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "073106e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = main_df.text.tolist() + gpt_filtered.text.tolist()\n",
    "len(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc1642",
   "metadata": {},
   "source": [
    "#### Get 500 top uni- and bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a49beb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf, top_indices, top_features = get_top_indices_and_vectorizer(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb2da3",
   "metadata": {},
   "source": [
    "#### Calculate TF-IDF per text for human-generated texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64a582cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"tfidf_{}\".format(gpt_source)] = main_df.text.apply(lambda x: calc_tfidf(x, tfidf, top_indices))\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "60184b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_df.to_pickle(\"Data/de_wiki_features_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4989a124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18e5f6f4",
   "metadata": {},
   "source": [
    "#### Calculate TF-IDF per text for AI-generated texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6056e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column \"tiidf\" if it does not exist yet\n",
    "#gpt_df[\"tfidf\"] = None\n",
    "\n",
    "for index, row in gpt_df.iterrows():\n",
    "    if row.source == gpt_source:\n",
    "        gpt_df.at[index, \"tfidf\"] = calc_tfidf(row.text, tfidf, top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58fb4b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_en</th>\n",
       "      <th>title_language</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>character_count</th>\n",
       "      <th>words_count</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>...</th>\n",
       "      <th>ppl_max</th>\n",
       "      <th>ppl_mean</th>\n",
       "      <th>sentence_bert</th>\n",
       "      <th>sentence_bert_dist</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Die Republik Österreich hat neun Bundesländer,...</td>\n",
       "      <td>1020</td>\n",
       "      <td>144</td>\n",
       "      <td>rephrase_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>41.739979</td>\n",
       "      <td>17.835852</td>\n",
       "      <td>[-0.0060472703, -0.0015850338, 0.012966703, 0....</td>\n",
       "      <td>0.718966</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Wien ist Österreichs Bundeshauptstadt und eine...</td>\n",
       "      <td>1167</td>\n",
       "      <td>155</td>\n",
       "      <td>rephrase_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>25.480711</td>\n",
       "      <td>16.853344</td>\n",
       "      <td>[-0.021692196, 0.0011809485, 0.02170519, 0.004...</td>\n",
       "      <td>0.703729</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Wien ist die Hauptstadt von Österreich und lie...</td>\n",
       "      <td>1840</td>\n",
       "      <td>264</td>\n",
       "      <td>generated_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>61.625816</td>\n",
       "      <td>19.912042</td>\n",
       "      <td>[-0.013687565, -0.0053922576, -0.0005174721, 0...</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.030498856144209132, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Wien, die österreichische Hauptstadt, ist eine...</td>\n",
       "      <td>1297</td>\n",
       "      <td>189</td>\n",
       "      <td>generated_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>24.912964</td>\n",
       "      <td>14.705893</td>\n",
       "      <td>[0.00030970015, -0.023622207, 0.031076685, 0.0...</td>\n",
       "      <td>0.715953</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.03894820279197, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Himalayas</td>\n",
       "      <td>Himalaya</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Asien beheimatet das höchste Gebirge der Erde,...</td>\n",
       "      <td>888</td>\n",
       "      <td>118</td>\n",
       "      <td>rephrase_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>72.549171</td>\n",
       "      <td>24.495172</td>\n",
       "      <td>[-0.0005591136, 0.035370592, -0.0149539765, -0...</td>\n",
       "      <td>0.663978</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Constitution</td>\n",
       "      <td>Verfassung</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>politics</td>\n",
       "      <td>Die Verfassung! Was für ein wichtiges Thema! D...</td>\n",
       "      <td>1771</td>\n",
       "      <td>247</td>\n",
       "      <td>generated_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>4847.800781</td>\n",
       "      <td>260.403628</td>\n",
       "      <td>[0.022768332, 0.0022064543, -0.0016067001, 0.0...</td>\n",
       "      <td>0.727045</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Fähigkeit von Atomen, bindende Elektronenp...</td>\n",
       "      <td>1517</td>\n",
       "      <td>196</td>\n",
       "      <td>rephrase_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>63.900864</td>\n",
       "      <td>26.798258</td>\n",
       "      <td>[-0.014504041, -0.01202015, -0.009371709, -0.0...</td>\n",
       "      <td>0.632077</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.03402081860285245, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Elektronegativität gibt an, wie gut ein At...</td>\n",
       "      <td>949</td>\n",
       "      <td>129</td>\n",
       "      <td>rephrase_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>68.056511</td>\n",
       "      <td>38.604194</td>\n",
       "      <td>[-0.014926519, -0.010599102, 0.00010431206, -0...</td>\n",
       "      <td>0.620899</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Elektronegativität beschreibt die Fähigkei...</td>\n",
       "      <td>1522</td>\n",
       "      <td>195</td>\n",
       "      <td>generated_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>31.118761</td>\n",
       "      <td>17.95147</td>\n",
       "      <td>[0.0018844944, -0.016691329, -0.03601046, -0.0...</td>\n",
       "      <td>0.624994</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Elektronegativität ist eine wichtige Eigen...</td>\n",
       "      <td>1505</td>\n",
       "      <td>201</td>\n",
       "      <td>generated_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>51.120129</td>\n",
       "      <td>24.584899</td>\n",
       "      <td>[-0.0013022688, -0.033272035, -0.027497053, -0...</td>\n",
       "      <td>0.567622</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title_en      title_language language        date   category  \\\n",
       "8                Vienna                Wien       de  2023-04-10  geography   \n",
       "9                Vienna                Wien       de  2023-04-10  geography   \n",
       "10               Vienna                Wien       de  2023-04-10  geography   \n",
       "11               Vienna                Wien       de  2023-04-10  geography   \n",
       "16            Himalayas            Himalaya       de  2023-04-10  geography   \n",
       "...                 ...                 ...      ...         ...        ...   \n",
       "1583       Constitution          Verfassung       de  2023-04-11   politics   \n",
       "1596  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "1597  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "1598  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "1599  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "\n",
       "                                                   text  character_count  \\\n",
       "8     Die Republik Österreich hat neun Bundesländer,...             1020   \n",
       "9     Wien ist Österreichs Bundeshauptstadt und eine...             1167   \n",
       "10    Wien ist die Hauptstadt von Österreich und lie...             1840   \n",
       "11    Wien, die österreichische Hauptstadt, ist eine...             1297   \n",
       "16    Asien beheimatet das höchste Gebirge der Erde,...              888   \n",
       "...                                                 ...              ...   \n",
       "1583  Die Verfassung! Was für ein wichtiges Thema! D...             1771   \n",
       "1596  Die Fähigkeit von Atomen, bindende Elektronenp...             1517   \n",
       "1597  Die Elektronegativität gibt an, wie gut ein At...              949   \n",
       "1598  Die Elektronegativität beschreibt die Fähigkei...             1522   \n",
       "1599  Die Elektronegativität ist eine wichtige Eigen...             1505   \n",
       "\n",
       "      words_count            source   author  ...      ppl_max    ppl_mean  \\\n",
       "8             144     rephrase_base  ChatGPT  ...    41.739979   17.835852   \n",
       "9             155   rephrase_expert  ChatGPT  ...    25.480711   16.853344   \n",
       "10            264    generated_base  ChatGPT  ...    61.625816   19.912042   \n",
       "11            189  generated_expert  ChatGPT  ...    24.912964   14.705893   \n",
       "16            118     rephrase_base  ChatGPT  ...    72.549171   24.495172   \n",
       "...           ...               ...      ...  ...          ...         ...   \n",
       "1583          247  generated_expert  ChatGPT  ...  4847.800781  260.403628   \n",
       "1596          196     rephrase_base  ChatGPT  ...    63.900864   26.798258   \n",
       "1597          129   rephrase_expert  ChatGPT  ...    68.056511   38.604194   \n",
       "1598          195    generated_base  ChatGPT  ...    31.118761    17.95147   \n",
       "1599          201  generated_expert  ChatGPT  ...    51.120129   24.584899   \n",
       "\n",
       "                                          sentence_bert  sentence_bert_dist  \\\n",
       "8     [-0.0060472703, -0.0015850338, 0.012966703, 0....            0.718966   \n",
       "9     [-0.021692196, 0.0011809485, 0.02170519, 0.004...            0.703729   \n",
       "10    [-0.013687565, -0.0053922576, -0.0005174721, 0...            0.741820   \n",
       "11    [0.00030970015, -0.023622207, 0.031076685, 0.0...            0.715953   \n",
       "16    [-0.0005591136, 0.035370592, -0.0149539765, -0...            0.663978   \n",
       "...                                                 ...                 ...   \n",
       "1583  [0.022768332, 0.0022064543, -0.0016067001, 0.0...            0.727045   \n",
       "1596  [-0.014504041, -0.01202015, -0.009371709, -0.0...            0.632077   \n",
       "1597  [-0.014926519, -0.010599102, 0.00010431206, -0...            0.620899   \n",
       "1598  [0.0018844944, -0.016691329, -0.03601046, -0.0...            0.624994   \n",
       "1599  [-0.0013022688, -0.033272035, -0.027497053, -0...            0.567622   \n",
       "\n",
       "      Fold_1  Fold_2  Fold_3  Fold_4  Fold_5  \\\n",
       "8       test   train   train   train   train   \n",
       "9       test   train   train   train   train   \n",
       "10      test   train   train   train   train   \n",
       "11      test   train   train   train   train   \n",
       "16     train   train   train   train   train   \n",
       "...      ...     ...     ...     ...     ...   \n",
       "1583   train   train   train   train   train   \n",
       "1596   train   train   train   train   train   \n",
       "1597   train   train   train   train   train   \n",
       "1598   train   train   train   train   train   \n",
       "1599   train   train   train   train   train   \n",
       "\n",
       "                                                  tfidf  \n",
       "8     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "10    [0.0, 0.0, 0.0, 0.030498856144209132, 0.0, 0.0...  \n",
       "11    [0.0, 0.0, 0.0, 0.0, 0.0, 0.03894820279197, 0....  \n",
       "16    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "1583  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1596  [0.0, 0.0, 0.0, 0.0, 0.03402081860285245, 0.0,...  \n",
       "1597  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1598  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1599  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[400 rows x 50 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d1f9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt_df.to_pickle(\"Data/de_gpt_features_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d489a0",
   "metadata": {},
   "source": [
    "## Create Sub-Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47f208f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngpt_en_rephr_b = news_feature_df[news_feature_df[\"source\"] == \"rephrase_base\"]\\ngpt_en_rephr_e = news_feature_df[news_feature_df[\"source\"] == \"rephrase_expert\"]\\ngpt_en_gen_b = news_feature_df[news_feature_df[\"source\"] == \"generated_base\"]\\ngpt_en_gen_e = news_feature_df[news_feature_df[\"source\"] == \"generated_expert\"]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter wiki df for language only\n",
    "wiki_de = wiki_df[wiki_df['language'] == \"de\"]\n",
    "\n",
    "gpt_de = gpt_df[gpt_df['language'] == \"de\"]\n",
    "\"\"\"\n",
    "gpt_en_rephr_b = news_feature_df[news_feature_df[\"source\"] == \"rephrase_base\"]\n",
    "gpt_en_rephr_e = news_feature_df[news_feature_df[\"source\"] == \"rephrase_expert\"]\n",
    "gpt_en_gen_b = news_feature_df[news_feature_df[\"source\"] == \"generated_base\"]\n",
    "gpt_en_gen_e = news_feature_df[news_feature_df[\"source\"] == \"generated_expert\"]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab60f9",
   "metadata": {},
   "source": [
    "## Create Feature DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c22d7b",
   "metadata": {},
   "source": [
    "### Define DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "009aa68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_en</th>\n",
       "      <th>title_language</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>character_count</th>\n",
       "      <th>words_count</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>gpt_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Die Republik Österreich hat neun Bundesländer,...</td>\n",
       "      <td>1020</td>\n",
       "      <td>144</td>\n",
       "      <td>rephrase_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, dieser Text wurde von ChatGPT generiert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Wien ist Österreichs Bundeshauptstadt und eine...</td>\n",
       "      <td>1167</td>\n",
       "      <td>155</td>\n",
       "      <td>rephrase_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, der Text wurde von ChatGPT generiert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Wien ist die Hauptstadt von Österreich und lie...</td>\n",
       "      <td>1840</td>\n",
       "      <td>264</td>\n",
       "      <td>generated_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Der Text wurde von einem menschlichen Autor ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>Wien</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Wien, die österreichische Hauptstadt, ist eine...</td>\n",
       "      <td>1297</td>\n",
       "      <td>189</td>\n",
       "      <td>generated_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, dieser Text wurde von ChatGPT generiert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Himalayas</td>\n",
       "      <td>Himalaya</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>geography</td>\n",
       "      <td>Asien beheimatet das höchste Gebirge der Erde,...</td>\n",
       "      <td>888</td>\n",
       "      <td>118</td>\n",
       "      <td>rephrase_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, der folgende Text wurde von ChatGPT generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Constitution</td>\n",
       "      <td>Verfassung</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>politics</td>\n",
       "      <td>Die Verfassung! Was für ein wichtiges Thema! D...</td>\n",
       "      <td>1771</td>\n",
       "      <td>247</td>\n",
       "      <td>generated_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, der folgende Text wurde von ChatGPT generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Fähigkeit von Atomen, bindende Elektronenp...</td>\n",
       "      <td>1517</td>\n",
       "      <td>196</td>\n",
       "      <td>rephrase_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, der folgende Text wurde von ChatGPT generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Elektronegativität gibt an, wie gut ein At...</td>\n",
       "      <td>949</td>\n",
       "      <td>129</td>\n",
       "      <td>rephrase_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, dieser Text wurde von ChatGPT generiert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Elektronegativität beschreibt die Fähigkei...</td>\n",
       "      <td>1522</td>\n",
       "      <td>195</td>\n",
       "      <td>generated_base</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, dieser Text wurde von ChatGPT generiert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Electronegativity</td>\n",
       "      <td>Elektronegativität</td>\n",
       "      <td>de</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>Die Elektronegativität ist eine wichtige Eigen...</td>\n",
       "      <td>1505</td>\n",
       "      <td>201</td>\n",
       "      <td>generated_expert</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>Ja, der Text wurde von ChatGPT generiert.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title_en      title_language language        date   category  \\\n",
       "8                Vienna                Wien       de  2023-04-10  geography   \n",
       "9                Vienna                Wien       de  2023-04-10  geography   \n",
       "10               Vienna                Wien       de  2023-04-10  geography   \n",
       "11               Vienna                Wien       de  2023-04-10  geography   \n",
       "16            Himalayas            Himalaya       de  2023-04-10  geography   \n",
       "...                 ...                 ...      ...         ...        ...   \n",
       "1583       Constitution          Verfassung       de  2023-04-11   politics   \n",
       "1596  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "1597  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "1598  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "1599  Electronegativity  Elektronegativität       de  2023-04-11  chemistry   \n",
       "\n",
       "                                                   text  character_count  \\\n",
       "8     Die Republik Österreich hat neun Bundesländer,...             1020   \n",
       "9     Wien ist Österreichs Bundeshauptstadt und eine...             1167   \n",
       "10    Wien ist die Hauptstadt von Österreich und lie...             1840   \n",
       "11    Wien, die österreichische Hauptstadt, ist eine...             1297   \n",
       "16    Asien beheimatet das höchste Gebirge der Erde,...              888   \n",
       "...                                                 ...              ...   \n",
       "1583  Die Verfassung! Was für ein wichtiges Thema! D...             1771   \n",
       "1596  Die Fähigkeit von Atomen, bindende Elektronenp...             1517   \n",
       "1597  Die Elektronegativität gibt an, wie gut ein At...              949   \n",
       "1598  Die Elektronegativität beschreibt die Fähigkei...             1522   \n",
       "1599  Die Elektronegativität ist eine wichtige Eigen...             1505   \n",
       "\n",
       "      words_count            source   author  \\\n",
       "8             144     rephrase_base  ChatGPT   \n",
       "9             155   rephrase_expert  ChatGPT   \n",
       "10            264    generated_base  ChatGPT   \n",
       "11            189  generated_expert  ChatGPT   \n",
       "16            118     rephrase_base  ChatGPT   \n",
       "...           ...               ...      ...   \n",
       "1583          247  generated_expert  ChatGPT   \n",
       "1596          196     rephrase_base  ChatGPT   \n",
       "1597          129   rephrase_expert  ChatGPT   \n",
       "1598          195    generated_base  ChatGPT   \n",
       "1599          201  generated_expert  ChatGPT   \n",
       "\n",
       "                                            gpt_feature  \n",
       "8          Ja, dieser Text wurde von ChatGPT generiert.  \n",
       "9             Ja, der Text wurde von ChatGPT generiert.  \n",
       "10    Der Text wurde von einem menschlichen Autor ge...  \n",
       "11         Ja, dieser Text wurde von ChatGPT generiert.  \n",
       "16    Ja, der folgende Text wurde von ChatGPT generi...  \n",
       "...                                                 ...  \n",
       "1583  Ja, der folgende Text wurde von ChatGPT generi...  \n",
       "1596  Ja, der folgende Text wurde von ChatGPT generi...  \n",
       "1597       Ja, dieser Text wurde von ChatGPT generiert.  \n",
       "1598       Ja, dieser Text wurde von ChatGPT generiert.  \n",
       "1599          Ja, der Text wurde von ChatGPT generiert.  \n",
       "\n",
       "[400 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gpt_de.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac290b81",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74ef6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"de\"\n",
    "lang_tool_lang = \"de-DE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4669505",
   "metadata": {},
   "source": [
    "### Derive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfbf44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# FEATURE ChatGPT ANSWER\n",
    "df = helper_functions.ordinal_gpt_feature(df)\n",
    "\n",
    "\n",
    "df['character_count'] = df.text.str.len()\n",
    "df['words_count'] = df.text.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "# FEATURE TITLE OCCURENCE\n",
    "df = helper_functions.title_occurence(df)\n",
    "\n",
    "# FEATURES FOR OCCURENCE OF WORDS\n",
    "#df = helper_functions.count_word_occurence(df, [\"the\", \"it\", \"is\", \"nevertheless\", \"although\", \"however\", \"therefore\"], add_blanks=True)\n",
    "\n",
    "# FEATURE FOR NUMBER OF SENTENCES\n",
    "df['sentence_count'] = helper_functions.count_sentences_raw_text(df, \"hybrid\")\n",
    "\n",
    "# FEATURE AVERAGE NUMBER OF WORDS PER SENTENCE\n",
    "#df[\"avg_words_per_sentence\"] = helper_functions.words_per_sentence(df)\n",
    "\n",
    "# FEATURE COUNT OF QUOTATION MARKS\n",
    "df['quotation_count'] = df['text'].str.count('\\\"')\n",
    "\n",
    "# FEATURE COUNT OF UNIQUE WORDS ABSOLUTE\n",
    "df[\"unique_words_count\"] = df.text.apply(lambda x: len(Counter(re.sub(r'[^A-Za-z \\n]', '', x).lower().split())))\n",
    "\n",
    "# FEATURE COUNT OF UNIQUE WORDS ABSOLUTE RELATIVE TO ALL WORDS IN TEXT\n",
    "df[\"unique_words_relative\"] = df[\"unique_words_count\"] / df[\"words_count\"]\n",
    "\n",
    "# FEATURE COUNT OF SPECIAL CHARACTERS\n",
    "pattern = r'[0-9a-z.?¿!¡,\\n çñáãâàîïíìóôòéèêúûùäöüß]'  # those are excluded from count -> removed from text\n",
    "df[\"special_char_count\"] = df.text.apply(lambda x: len(re.sub(pattern,'', x.lower())))\n",
    "\n",
    "df = helper_functions.add_flesch_scores(df)\n",
    "\n",
    "df[\"personal_pronoun_relative\"] = df.text.apply(lambda x: helper_functions.count_personal_pronouns(x, \"rel\", lang))\n",
    "df[\"personal_pronoun_count\"] = df.text.apply(lambda x: helper_functions.count_personal_pronouns(x, \"abs\", lang))\n",
    "\n",
    "df[\"stats\"] = df[\"text\"].apply(helper_functions.calculate_paragraph_stats)\n",
    "df[[\"words_per_paragraph_mean\", \"words_per_paragraph_stdev\", \"sentences_per_paragraph_mean\", \"sentences_per_paragraph_stdev\"]] = pd.DataFrame(df[\"stats\"].tolist(), index=df.index)\n",
    "# Drop the original 'stats' column\n",
    "df.drop(columns=[\"stats\"], inplace=True)\n",
    "df[\"punctuation_count\"] = df.text.apply(helper_functions.count_punctuation)\n",
    "\n",
    "df[\"paragraph_count\"] = df.text.apply(helper_functions.count_paragraphs)\n",
    "\n",
    "df[\"pos_per_sentence_mean\"] = df.text.apply(lambda x: helper_functions.get_avg_pos_types(x, lang))\n",
    "\n",
    "df[\"stats\"] = df[\"text\"].apply(helper_functions.get_sentence_stats)\n",
    "df[[\"unique_words_per_sentence_mean\", \"unique_words_per_sentence_stdev\", \"words_per_sentence_mean\", \"words_per_sentence_stdev\"]] = pd.DataFrame(df[\"stats\"].tolist(), index=df.index)\n",
    "# Drop the original 'stats' column\n",
    "df.drop(columns=[\"stats\"], inplace=True)\n",
    "\n",
    "df[\"uppercase_letters_relative\"] = df.text.apply(helper_functions.uppercase_percentage)\n",
    "df[\"discourse_marker_count\"] = df.text.apply(lambda x: helper_functions.discourse_marker_count(x, lang))\n",
    "df[\"stop_word_count\"] = df.text.apply(lambda x: helper_functions.count_stopwords(x, lang))\n",
    "df[\"multi_blank_count\"] = df.text.apply(helper_functions.count_double_blanks)\n",
    "\n",
    "\n",
    "import language_tool_python\n",
    "\n",
    "if lang == \"en\" or lang == \"fr\" or lang == \"es\":\n",
    "    # FEATURE LANGUAGE FINDINGS\n",
    "    tool = language_tool_python.LanguageTool(lang_tool_lang)\n",
    "    df['grammar_error_count'] = df.text.apply(lambda x: len(tool.check(x)))\n",
    "else:\n",
    "    tool = language_tool_python.LanguageToolPublicAPI(lang_tool_lang)\n",
    "    df[\"grammar_error_count\"] = None\n",
    "    for index, row in df.iterrows():\n",
    "        print(index)\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        error_count = 0\n",
    "        for sentence in sentences:\n",
    "            error_count += len(tool.check(sentence))\n",
    "        df.at[index, 'grammar_error_count'] = error_count\n",
    "\n",
    "df[\"sentiment\"] = df.text.apply(lambda x: helper_functions.get_sentiment(x, lang))\n",
    "df[[\"sentiment_polarity\", \"sentiment_subjectivity\"]] = pd.DataFrame(df[\"sentiment\"].tolist(), index=df.index)\n",
    "# Drop the original 'sentiment' column\n",
    "df.drop(columns=[\"sentiment\"], inplace=True)\n",
    "\n",
    "\n",
    "# FEATURE PERPLEXITY\n",
    "df = helper_functions.add_perplexity(df, lang)\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "df[\"sent_vec_stats\"] = df.text.apply(lambda x: helper_functions.sentence_vector_mean_vector_and_distance(x, model))\n",
    "df[[\"sentence_bert\", \"sentence_bert_dist\"]] = pd.DataFrame(df[\"sent_vec_stats\"].tolist(), index=df.index)\n",
    "df.drop(columns=[\"sent_vec_stats\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93717c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4887139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"Data/en_gpt_features_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
